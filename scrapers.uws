// 動作確認
if GET_UWSC_NAME == 'scrapers.uws' then
    scrapers = [
        StarWalk,
        KodamaMaria,
        UtyuYabai,
    ]
    for cls in scrapers
        if f := cls().scrape() then
            print f
        else
            print '更新なし'
        endif
    next
endif

class Feed
    public title
    public url
    public summary
    public updated
    // constructor
    procedure Feed(title, url, summary, updated = EMPTY)
        this.title = title
        this.url = url
        this.summary = summary
        if updated == EMPTY then
            now = gettime()
            // this.updated = format(now, '%+')
            this.updated = now
        else
            this.updated = updated
        endif
    fend
    procedure print()
        print "<#title><#CR><#url><#CR><#summary>"
    fend
endclass

function get_feed_object(title, link, description)
    result = @{
        "title": null,
        "link": null,
        "pubDate": null,
        "description": null
    }@
    result.title = title
    result.link = link
    result.description = description
    result.pubDate = as_pubdate(gettime())
fend

function as_pubdate(updated)
    pubdate = format(updated, '%a, %h %Y %T %z')
    result = replace_dm(pubdate)
fend

function replace_dm(pubdate)
    for month in [[' 1月', 'Jan'], [' 2月', 'Feb'], [' 3月', 'Mar'], [' 4月', 'Apr'], [' 5月', 'May'], [' 6月', 'Jun'], [' 7月', 'Jul'], [' 8月', 'Aug'], [' 9月', 'Sep'], ['10月', 'Oct'], ['11月', 'Nov'], ['12月', 'Dec']]
        if pos(month[0], pubdate) > 0 then
            pubdate = replace(pubdate, month[0], month[1])
            break
        endif
    next
    for day in [['日', 'Sun'], ['月', 'Mon'], ['火', 'Tue'], ['水', 'Wed'], ['木', 'Thu'], ['金', 'Fri'], ['土', 'Sat']]
        if pos(day[0], pubdate) > 0 then
            pubdate = replace(pubdate, day[0], day[1])
            break
        endif
    next
    result = pubdate
fend

class StarWalk
    dim url = 'https://webcomicgamma.takeshobo.co.jp/manga/starwalk/'
    procedure StarWalk()
    fend
    function scrape()
        dim key = 'スターウォーク'
        result = EMPTY
        tab = FeedScraperHelper.browser.new(url)
        try
            link = tab.document.querySelector('div.read__outer a')
            if FeedScraperHelper.check(key, link.id) then
                title = trim( link.querySelector('.episode').textContent )
                summary = '公開日: ' + link.querySelector('.episode__text').textContent
                result = get_feed_object(title, link.href, summary)
                FeedScraperHelper.update(key, link.id)
            endif
        except
            result = get_feed_object("[解析エラー] <#key>", url, "<#TRY_ERRLINE><#CR><#TRY_ERRMSG>")
        endtry
        tab.close()
    fend
endclass

class UtyuYabai
    dim url = 'https://webcomicgamma.takeshobo.co.jp/manga/uchuuyabai/'
    procedure UtyuYabai()
    fend
    function scrape()
        dim key = 'ウは宇宙ヤバイのウ！'
        result = EMPTY
        tab = FeedScraperHelper.browser.new(url)
        try
            link = tab.document.querySelector('div.read__outer a')
            if FeedScraperHelper.check(key, link.id) then
                title = trim( link.querySelector('.episode').textContent )
                summary = '公開日: ' + link.querySelector('.episode__text').textContent
                result = get_feed_object(title, link.href, summary)
                FeedScraperHelper.update(key, link.id)
            endif
        except
            result = get_feed_object("[解析エラー] <#key>", url, "<#TRY_ERRLINE><#CR><#TRY_ERRMSG>")
        endtry
        tab.close()
    fend
endclass

class KodamaMaria
    dim url = 'https://to-ti.in/product/mariakodama'
    procedure KodamaMaria()
    fend
    function scrape()
        dim key = '児玉まりあ文学集成'
        result = EMPTY

        tab = FeedScraperHelper.browser.new(url)
        try
            link = tab.document.querySelector('.next a')
            if FeedScraperHelper.check(key, link.href) then
                title = trim( link.querySelector('span.typesquare_option').textContent )
                summary = trim( tab.document.querySelector('header time').textContent )
                result = get_feed_object(title, link.href, summary)
                FeedScraperHelper.update(key, link.href)
            endif
        except
            result = get_feed_object("[解析エラー] <#key>", url, "<#TRY_ERRLINE><#CR><#TRY_ERRMSG>")
        endtry
        tab.close()
    fend

endclass

module FeedScraperHelper
    const HEADLESS = FALSE
    const MANGA_FEED_PROFILE_DIR = "<#GET_CUR_DIR>\profile\"
    // const ERROR_LOG = 'D:\manga_feed\error.log'
    public browser
    // constructor
    procedure FeedScraperHelper
        browser = browserbuilder(BC_MSEDGE)_
            .headless(HEADLESS)_
            .profile(MANGA_FEED_PROFILE_DIR)_
            .start()
    fend

    const ini = 'manga_feed.ini'
    const section = 'manga_feed'

    function check(key, value)
        recent = readini(section, key, ini)
        result = value != recent
    fend

    procedure update(key, value)
        writeini(section, key, value, ini)
    fend

    // procedure error(msg)
    //     fid = fopen(ERROR_LOG, F_WRITE8 or F_AUTOCLOSE)
    //     fput(fid, msg)
    // fend
endmodule
